{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85YB9Ss05snk"
   },
   "source": [
    "---\n",
    "\n",
    "  # Deep Learning and VGG16 Transfer Learning based Flower Recognition\n",
    "This is the code for the project entitled \"**Deep Learning and VGG16 Transfer Learning based Flower Recognition**\" submitted as the course project of **ECE 9039@UWO**<br>  \n",
    "Author: Zhijun Li (zli2945@uwo.ca) and Liang Zhang (lzha46@uwo.ca)<br>\n",
    "Date: 01 March, 2023<br>\n",
    "  \n",
    "\n",
    "**Notebook 0: Only valid for Grid Search HPO process for number of layers in hand-designed CNN model**  \n",
    "Purpose:  \n",
    "&nbsp; 1): Find the optimzied number of layers in conv2d model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EceSoBuNbEyV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ignore the warnings for smooth progress\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#import tensorflow as tf\n",
    "#import random as rn\n",
    " \n",
    "# data preparation\n",
    "import cv2           \n",
    "import os  \n",
    "\n",
    "# data preprocess\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# model selection and evaluation metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,\\\n",
    "confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# cnn model libraraies\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D  \n",
    "    \n",
    "# HPO related\n",
    "from hyperopt import hp, fmin, rand, STATUS_OK\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhiOBqTissSr",
    "outputId": "a4eb3b93-bd3d-4c89-d5ed-477b4587820f"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LvFuvtYqrzxq"
   },
   "outputs": [],
   "source": [
    "def dataset_prep(flower_name_list, train_or_test): \n",
    "    #IMG_SIZE=224 #150\n",
    "    folder_name = 'example_modify_dataset'\n",
    "    \n",
    "    for flower_name in flower_name_list:\n",
    "        Opt_DataCnt = 0\n",
    "        full_path = os.path.join(folder_name, train_or_test, flower_name)\n",
    "\n",
    "        # os.listdir: get all files under DIR\n",
    "        for pic in os.listdir(full_path):\n",
    "            pic_path = os.path.join(full_path,pic) #full_path + '/' + pic\n",
    "            # read img from path with default setting 'IMREAD_COLOR'\n",
    "            this_pic = cv2.imread(pic_path, cv2.IMREAD_COLOR)\n",
    "            this_pic = cv2.resize(this_pic, (IMG_SIZE, IMG_SIZE))\n",
    "            if(train_or_test == 'train'):\n",
    "                X_train.append(np.array(this_pic))\n",
    "                y_train.append(str(flower_name))\n",
    "                if(Opt_DataCnt < 200):\n",
    "                    X_train_HPO.append(np.array(this_pic))\n",
    "                    y_train_HPO.append(str(flower_name))\n",
    "            elif(train_or_test == 'test'):\n",
    "                X_test.append(np.array(this_pic))\n",
    "                y_test.append(str(flower_name))\n",
    "            else:\n",
    "                print(\"Error! input 'train_or_test'-{0} is not supported!\".format(train_or_test))\n",
    "                break\n",
    "            Opt_DataCnt += 1\n",
    "        print(\"Finish processing {0}\\nX_train's size: {1:5d}\\tX_test's size: {2}\\\n",
    "        y_train's size: {3:5d}\\ty_test's size: {4}\\n\".format(flower_name,len(X_train),len(X_test),len(y_train),len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCnQYNVJrzxq",
    "outputId": "0b7dfc54-34bc-4551-a314-ccbbefb5393f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish processing daisy\n",
      "X_train's size:   754\tX_test's size: 0        y_train's size:   754\ty_test's size: 0\n",
      "\n",
      "Finish processing dandelion\n",
      "X_train's size:  1796\tX_test's size: 0        y_train's size:  1796\ty_test's size: 0\n",
      "\n",
      "Finish processing rose\n",
      "X_train's size:  2570\tX_test's size: 0        y_train's size:  2570\ty_test's size: 0\n",
      "\n",
      "Finish processing sunflower\n",
      "X_train's size:  3293\tX_test's size: 0        y_train's size:  3293\ty_test's size: 0\n",
      "\n",
      "Finish processing tulip\n",
      "X_train's size:  4267\tX_test's size: 0        y_train's size:  4267\ty_test's size: 0\n",
      "\n",
      "\n",
      "\n",
      "Finish processing daisy\n",
      "X_train's size:  4267\tX_test's size: 10        y_train's size:  4267\ty_test's size: 10\n",
      "\n",
      "Finish processing dandelion\n",
      "X_train's size:  4267\tX_test's size: 20        y_train's size:  4267\ty_test's size: 20\n",
      "\n",
      "Finish processing rose\n",
      "X_train's size:  4267\tX_test's size: 30        y_train's size:  4267\ty_test's size: 30\n",
      "\n",
      "Finish processing sunflower\n",
      "X_train's size:  4267\tX_test's size: 40        y_train's size:  4267\ty_test's size: 40\n",
      "\n",
      "Finish processing tulip\n",
      "X_train's size:  4267\tX_test's size: 50        y_train's size:  4267\ty_test's size: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "X_train_HPO = []\n",
    "y_train_HPO = []\n",
    "IMG_SIZE=224 #150\n",
    "    \n",
    "flower_name_list = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "dataset_prep(flower_name_list, 'train')\n",
    "print(\"\\n\")\n",
    "dataset_prep(flower_name_list, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9Iiskr-dvsx2"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QR67IE2VCWs_"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3DBzJyn1rzxr"
   },
   "outputs": [],
   "source": [
    "def XY_prep(X, y): \n",
    "    # label encoding\n",
    "    le=LabelEncoder()\n",
    "    y=le.fit_transform(y)\n",
    "    # transform Y to binary one-hot encoding\n",
    "    y=to_categorical(y,5)\n",
    "    X=np.array(X)\n",
    "    # Convergence, scaling the pixel values between [0, 1], avoids neuron fall into 'death zone'\n",
    "    X=X/255\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2COliyGMrzxr",
    "outputId": "b68286f1-9602-4ab7-d68d-6935beab00e3"
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    print('train:')\n",
    "    print(np.shape(X_train))\n",
    "    print(np.shape(y_train))\n",
    "    print('test:')\n",
    "    print(np.shape(X_test))\n",
    "    print(np.shape(y_test))\n",
    "    print('train_HPO:')\n",
    "    print(np.shape(X_train_HPO))\n",
    "    print(np.shape(y_train_HPO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yW0wKBgsrzxr"
   },
   "outputs": [],
   "source": [
    "X_train_coded, y_train_coded = XY_prep(X_train, y_train)\n",
    "X_test_coded, y_test_coded = XY_prep(X_test, y_test)\n",
    "X_train_HPO_coded, y_train_HPO_coded = XY_prep(X_train_HPO, y_train_HPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7C5Ms36rzxs",
    "outputId": "efbe49d8-ba47-42ce-b6a2-af77898e3c43"
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    print('train_coded:')\n",
    "    print(np.shape(X_train_coded))\n",
    "    print(np.shape(y_train_coded))\n",
    "    print('test_coded:')\n",
    "    print(np.shape(X_test_coded))\n",
    "    print(np.shape(y_test_coded))\n",
    "    print('train_HPO_coded:')\n",
    "    print(np.shape(X_train_HPO_coded))\n",
    "    print(np.shape(y_train_HPO_coded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjJeXKvNDul1"
   },
   "source": [
    "## HPO method construction and execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 11:34:46.061518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'num_layers': 4}\n",
      "Best accuracy score:  0.553044060866038\n"
     ]
    }
   ],
   "source": [
    "def Grid_Search_CNN_Layers(num_layers = 1):\n",
    "    # create a sequential model object\n",
    "    myGSModel = Sequential()\n",
    "    if(num_layers >= 1):\n",
    "      # add an input layer with hidden_neurons units\n",
    "      myGSModel.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "      myGSModel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    if(num_layers >= 2):\n",
    "      myGSModel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "      myGSModel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    if(num_layers >= 3):\n",
    "      myGSModel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "      myGSModel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    if(num_layers >= 4):\n",
    "      myGSModel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "      myGSModel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    # convert multidimension into one dimension\n",
    "    myGSModel.add(Flatten())\n",
    "    myGSModel.add(Dense(512))\n",
    "    myGSModel.add(Activation('relu'))\n",
    "    # below 5 is the number of flowers' classes\n",
    "    myGSModel.add(Dense(5, activation = \"softmax\"))\n",
    "    \n",
    "    # compile the model specifying an optimizer and a loss function\n",
    "    myGSModel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return myGSModel\n",
    "\n",
    "### Grid Search\n",
    "param_grid = {\n",
    "    'num_layers': [1, 2, 3, 4]\n",
    "}\n",
    "# to use a keras model with sklearn we need to call a wrapper function where the build function is Grid_Search_NN_model\n",
    "hp_model = KerasClassifier(build_fn=Grid_Search_CNN_Layers, verbose=0)\n",
    "# instantiate gridsearch object using 3 fold crossvaliadtion\n",
    "grid=GridSearchCV(estimator = hp_model, param_grid = param_grid, refit=True, cv=3)\n",
    "# fit the gridsearch object on the data\n",
    "grid_result = grid.fit(X_train_HPO, y_train_HPO, epochs=10, verbose=0)\n",
    "# determine the best parameter and the best score (it is accuracy in metrics so it is best accuracy score)\n",
    "print('Best parameters: ', grid_result.best_params_)\n",
    "print('Best accuracy score: ', grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
